{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORLwNv1tvSGuXlJ4ifJbA3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shauryay7/Youtube-Transcript/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **YouTube Transcript**\n",
        "\n",
        "`language` use the language code to get the video.\n",
        "\n",
        "`punctuation_model` values can be found at https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large#languages"
      ],
      "metadata": {
        "id": "lzGAjCEkKUtp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8LoK1RxKHXs"
      },
      "outputs": [],
      "source": [
        "!pip install youtube-transcript-api deepmultilingualpunctuation nltk google-api-python-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NTQ_f0QXKpXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://youtu.be/Sx6dAx7dnXg?si=xBMYxgT8r0D2vQkT'\n",
        "language = 'en'\n",
        "punctuated = True\n",
        "output_dir = '.'\n",
        "filename = \"\"\n",
        "punctuation_model = ''\n",
        "verbose = True"
      ],
      "metadata": {
        "id": "bSDHxsuPKzW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # To store file in Drive"
      ],
      "metadata": {
        "id": "CAh7ip0QK6y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "import nltk\n",
        "import youtube_transcript_api\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "\n",
        "from google.colab import userdata\n",
        "import warnings"
      ],
      "metadata": {
        "id": "Bf_FN74tLGkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, force=True)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tN1BO662LJsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_for_filename(title):\n",
        "    cleaned_title = re.sub(r'[^\\w\\s\\.\\-\\(\\)\\[\\]]', '', title)\n",
        "    return cleaned_title.strip()\n",
        "\n",
        "def remove_music_tags(text):\n",
        "    updated_text = re.sub(r'\\[music\\]', '', text, flags=re.IGNORECASE)\n",
        "    return updated_text\n",
        "\n",
        "def remove_period_after_hashes(text):\n",
        "    return re.sub(r'(#\\.|##\\.)', lambda match: match.group(1)[:-1], text)\n",
        "\n",
        "def remove_escape_sequences(text):\n",
        "    # Some old videos contain escape sequences like \\n.\n",
        "    return re.sub(r'\\\\[nrtb]|\\\\r\\n', '', text)\n",
        "\n",
        "def remove_double_greater_than(text):\n",
        "    cleaned_text = re.sub(r'>>', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def add_punctuation(text, punctuation_model):\n",
        "    if punctuation_model != \"\":\n",
        "        model = PunctuationModel(model=punctuation_model)\n",
        "    else:\n",
        "        model = PunctuationModel()\n",
        "        punctuated_text = model.restore_punctuation(text)\n",
        "    return punctuated_text\n",
        "\n",
        "def capitalize_sentences(sentences):\n",
        "    capitalized_sentences = [sentence[0].upper() + sentence[1:] for sentence in sentences]\n",
        "    return capitalized_sentences\n",
        "\n",
        "def parse_youtube_url(url):\n",
        "    video_id_match = re.search(r'(?:youtube\\.com\\/.*?[?&]v=|youtu\\.be\\/)([^\"&?\\/\\s]{11})', url)\n",
        "    if video_id_match:\n",
        "        return video_id_match.group(1)\n",
        "    else:\n",
        "        raise ValueError('Invalid YouTube URL')\n",
        "\n",
        "def parse_chapters(description):\n",
        "    lines = description.split(\"\\n\")\n",
        "    regex = re.compile(r\"(\\d{0,2}:?\\d{1,2}:\\d{2})\")\n",
        "    chapters = []\n",
        "\n",
        "    for line in lines:\n",
        "        matches = regex.findall(line)\n",
        "        if matches:\n",
        "            ts = matches[0]\n",
        "            title = line.replace(ts, \"\").strip()\n",
        "            title = re.sub(r'\\d{0,2}:?\\d{1,2}:\\d{2}', '', title).strip().strip('-').strip().strip('-').strip()\n",
        "\n",
        "            chapters.append({\n",
        "                \"timestamp\": ts,\n",
        "                \"title\": title,\n",
        "            })\n",
        "\n",
        "    return chapters\n",
        "\n",
        "def get_transcript(video_id, language, video_info, verbose=True):\n",
        "    transcript_list = youtube_transcript_api.YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
        "\n",
        "    if video_info[\"title\"] != \"\":\n",
        "        transcript = f'# {video_info[\"title\"]}\\n\\n'\n",
        "\n",
        "    current_chapter_index = 0\n",
        "    chapters = video_info[\"chapters\"]\n",
        "    logging.info(f\"Transcript_List Length: {len(transcript_list)}, Chapter Length: {len(chapters)}\")\n",
        "\n",
        "    for i, line in enumerate(transcript_list):\n",
        "        start_time = int(math.floor(line['start']))\n",
        "        if 0 <= current_chapter_index < len(chapters):\n",
        "            chapter_time = chapters[current_chapter_index]['timestamp']\n",
        "\n",
        "            try:\n",
        "                chapter_start = chapter_time.strip()\n",
        "                chapter_start_seconds = sum(int(x) * 60 ** i for i, x in enumerate(reversed(chapter_start.split(':'))))\n",
        "                chapters[current_chapter_index][\"title\"] = chapters[current_chapter_index][\"title\"].strip()\n",
        "                buffer_time = 2\n",
        "\n",
        "                if start_time >= chapter_start_seconds - buffer_time:\n",
        "                    logging.info(f'\\n\\n## {chapters[current_chapter_index][\"title\"]}\\n')\n",
        "                    current_chapter_index += 1\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing chapter timestamp: {chapter_time}\")\n",
        "                logging.error(f\"Error details: {e}\")\n",
        "\n",
        "        line['text'] = remove_music_tags(line['text'])\n",
        "        line['text'] = remove_escape_sequences(line['text'])\n",
        "        line['text'] = remove_double_greater_than(line['text'])\n",
        "        if line['text']:\n",
        "          transcript += line['text'].strip() + ' '\n",
        "\n",
        "        if verbose and i % 100 == 0:\n",
        "            logging.info(f\"Processed {i} lines out of {len(transcript_list)}\")\n",
        "\n",
        "    return transcript\n",
        "\n",
        "def process_and_save_transcript(video_id, video_info, language, generate_punctuated, output_dir, filename, verbose, punctuation_model):\n",
        "    try:\n",
        "        raw_transcript = get_transcript(video_id, language, video_info, verbose)\n",
        "        logging.info(\"Raw Transcript Length: %d\", len(raw_transcript))\n",
        "\n",
        "        if generate_punctuated:\n",
        "            with_punctuation = add_punctuation(raw_transcript, punctuation_model)\n",
        "            with_punctuation = remove_period_after_hashes(with_punctuation)\n",
        "            logging.info(\"Punctuation Char Length: %d\", len(with_punctuation))\n",
        "            sentences = nltk.sent_tokenize(with_punctuation)\n",
        "            logging.info(\"Sentences to process, (punctuated): %d\", len(sentences))\n",
        "        else:\n",
        "            sentences = nltk.sent_tokenize(raw_transcript)\n",
        "            logging.info(\"Sentences to process, (raw): %d\", len(sentences))\n",
        "\n",
        "        capitalized_sentences = capitalize_sentences(sentences)\n",
        "\n",
        "        double_linesep = os.linesep + os.linesep\n",
        "        capitalized_transcript = double_linesep.join(capitalized_sentences)\n",
        "        output_path = os.path.join(output_dir, f'{filename}.md')\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(capitalized_transcript)\n",
        "\n",
        "        if generate_punctuated:\n",
        "            logging.info(f'Punctuated transcript saved to {output_path}')\n",
        "        else:\n",
        "            logging.info(f'Raw transcript saved to {output_path}')\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f'Error: {e}')\n",
        "\n",
        "def getVideoInfo (video_id):\n",
        "  try:\n",
        "    api_key =  userdata.get('YOUTUBE_API_KEY') # Replace with your actual API key\n",
        "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "    request = youtube.videos().list(part=\"id,snippet\",\n",
        "                                id = video_id\n",
        "        )\n",
        "    response = request.execute()\n",
        "    title = response['items'][0]['snippet']['title']\n",
        "    description = response['items'][0]['snippet']['description']\n",
        "    data = {\"title\" : title, \"chapters\" : parse_chapters(description)}\n",
        "    return data\n",
        "  except Exception as e:\n",
        "    logging.error(f'Error: {e}')\n",
        "    return {\"title\": \"\", \"chapters\": []}"
      ],
      "metadata": {
        "id": "MxJ0enaxMQLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = parse_youtube_url(url)\n",
        "video_info = getVideoInfo(video_id)\n",
        "filename = filename = filename or clean_for_filename(video_info[\"title\"]) or clean_for_filename(video_id)"
      ],
      "metadata": {
        "id": "rTvNjC2cMfT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_and_save_transcript(video_id, video_info, language, punctuated, output_dir, filename, verbose, punctuation_model)"
      ],
      "metadata": {
        "id": "guABgwwjMjX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Generated File\n",
        "from google.colab import files\n",
        "files.download(os.path.join(output_dir, f'{filename}.md'))"
      ],
      "metadata": {
        "id": "ETwkxktyMlHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}